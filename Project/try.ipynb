{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 0s 1ms/step - loss: -3.6955e-10 - accuracy: 0.0000e+00 - val_loss: -1.4143e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "46/90 [==============>...............] - ETA: 0s - loss: -4.8037e-10 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e4f3c69dadb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# model fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# score trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "x_train = np.random.randn(10000,13)\n",
    "y_train = np.random.randn(10000,1)\n",
    "\n",
    "x_test = np.random.randn(100,13)\n",
    "y_test = np.random.randn(100,1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(13))\n",
    "model.add(keras.layers.Dense(8,activation='relu'))\n",
    "model.add(keras.layers.Dense(4,activation='relu'))\n",
    "model.add(keras.layers.Dense(1,activation='relu'))\n",
    "model.summary()\n",
    "\n",
    "# optimizer & loss function & metric\n",
    "opt = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# model compile\n",
    "model.compile(loss=loss_fn,optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "# model fit\n",
    "history = model.fit(x=x_train,y=y_train,epochs=200,batch_size=100,validation_split=0.1,verbose=True)\n",
    "\n",
    "# score trained model\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 400692145055525909\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5680903083165377648\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6531337689\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1748018945121936992\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3477387660492724460\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
